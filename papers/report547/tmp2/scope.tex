%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Scope}
\label{sec:scope}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Our initial distributed trace time curve visualization suffered a number of
shortcommings. Mainly the time to compute the time curve using tsne was too
slow, on the order of 8-10 minutes for the traces we wished to analyze. Such a
compute time is problematic for us because we wished to achive interactive
recomputation of the time curve by biasing clusters towards variables that
users marked as important. The leading cause of our visualizations compute time
was the single threaded JavaScript archetecture we used to run tsne. Another
shortcomming of our visualization was the lack of labels on clusters, and the
size of invariants generated for a single trace. T-SNE generates visual
clusterings, but not logicial ones, so no further computation can be done to
the clusters. Daikon, our tool for inferring distributed invariants, outputs
all of its template invariants which are not violated during an execution. This
number can be large, and many invariants are spurious. In the following section
we discribe our archetectural shift from JavaScript to Go, the implementation
of an effienct parrallel t-SNE, our back end support for skewing t-SNE
clustering towards important variables. Further, we disribe our algorithm for
computing visual t-SNE cluster into logical ones, our approach for calculating
cluster invariants, and their subset of unique cluster invariants.

\subsection{JavaScript to Go}
\label{sec:js2go}

JavaScript has many convienient frameworks for builing client server
applications which are compatable with nearly all browsers. This fact lead us
to develop our time curve prototype in a mixture of React~\cite{react}, and
node.js~\cite{node.js}. Calculating XOR distance on our target traces was
sufficiently slow with this framework that we cached results and served
precomputed distance from our node.js server. Figure\todo{reference orignal
javascript arcetecture} outlines our original archetecture. T-SNE coordinates
were calculated client side, at latencies of ~30s. To achieve our goal of
interactivity we desinged a new archetecture with a thin client, which issues
computation requests to an optimized server written in Go. Our choice of Go was
due to its concurrancy language primitives and increased performance. In
section ~\ref{sec:imp} we discuss the details of our implementation.

\subsection{Parallel t-SNE}
\label{sec:ptsne}
t-SNE is a ML algorithm for dimensionality reduction. We leverage t-SNE as the
state space of a trace point can be modeled as a high dimensional vector where
each variable is a dimension with a magnitude equal to it's binary encoding. At
it's core each itteration of t-SNE has 4 steps. First a cost gradent is
calculated, using a distance function, second the gradent is normalized, third
the gradent moves all projected points a distance, last the momentum of each
point is updated for the next step, and the points are reprojected. Each stage
of this algorithm has a data dependency on its prior step, therefore there is
no trivial method for parallizing t-SNE. Our solution requires that seperate
threads are delegated points for which they must compute values, and a master
thread which coordinates barriers to protected against inconsistant memory
accesses.



\noindent\textbf{XOR Distance:} A single point in a distributed trace can
consist of hundreds of variables.  Computing the distance between any
two points requires that we calculate XOR on each variable pair, and
then calculate the euclidean norm of each. Our typical traces consist
of ~100-300 variables per trace, and 100 trace points. As t-SNE is
$O(n^2)$ per itteration, requiring aproximatly 20 itterations for
reasonable results we end up with a typical number of XOR computations
in the order of ((300*300)/2)*100 * 20 ~100M XOR computations. We
aliviate much of this complexity by precomputing XOR distance for each
pairs of points and caching them. By doing so we only incur the full
cost of running XOR distance for a single itteration of t-SNE.


\subsection{variable weighting and distance reporting}

Figure~\ref{}\todo{make a graph with two unknown poitns} is an example
visualization generated by our original tool. At a glance the image is
composed of \todo{x} clusters, with no semantic meaning behind them.
In fact this is a distributed key value store responding to a 50\%
put, and 50\% get workload. Under the assumption that users would
generate their own traces from test cases, we assume that they will
have some understanding of the high level functional behaviour of
their system. To help developers reason precisely about clusters we
aimed to answer the question \emph{Why is point A distant from point
B?}.\todo{talk a bit about implementation?} 

\subsection{Cluster Detection, and Invariants}

The results of running t-SNE on high dimensional data are visual
clusters of points. While these points are usefull for descerning
patterns in a trace, but as they are visual, they are not available
for further analysis without an additional processing. We propose the
use of k-means clustering on t-SNE output, to logically cluster visual
clusters. Alternative density clustering techniques such as
DBSCAN~\cite{}\todo{cite dbscan} have greater precision at detecting
clusters automatically, our choice of k-means is to allow users to
select the number of clusters they observere.

\textbf{Cluster Invariants, and Unique Cluster Invariants}

Logical clusters detected by k-means, can be further prosessed in
isolation from other clusters. Our prototype tool output distributed
data invariants which held over an entire execution. These invariants
are course grain, and do not expose invariant behaviour of individual
clusters.  
%
Daikon outputs all template invariants which are not violated by a
trace, and which are supported by entries in a trace up to a minimal
confidence measure. Applying daikon to individual clusters has the
downside that the number of detected invariants grows, as there is
less evidence to invalidate spurious invariants. We propose that
invariants unique to clusters identify their most interesting
behaviour. To detect unique invariants we compair each cluster with
all others using Daikons \emph{Invariant Checker} tool. Unique
invariants for a cluster, are invariants which are violated by all
other clusters.



