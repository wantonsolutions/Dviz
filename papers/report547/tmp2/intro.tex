%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction and Motivation}
\label{sec:intro}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


The complexities of distributed systems have long plagued their
developers. Writing code which executes on various machines is
intrinsically more complicated due to networking eccentricities, such
as failures, partitions, and message delays. Debugging and checking
the correctness of such systems is laborious and technical, as
developers must inspect large logs for small discrepancies in expected
values, and timestamps. At scale auxiliary tools are necessary for
interpreting logs and making them accessible. Typically tracing tools
are used to reconstruct the communication of nodes throughout a
system, order their events, and present developers with a
comprehensive view of an execution.
%%
    Tracing tools alone still produce large amounts of data, albeit
    their structure is more understandable than raw logs. Typically
    tracing tools are equipped with a visual front end, allowing users
    to quickly observe the behaviour of executions, and under scrutiny
    identify irregular or bugging behaviour. No one tracing technique
    is sufficient for debugging distributed systems. While all tracing
    tools are concerned with debugging they typically fall into 3 sub
    categories of performance tuning, distributed control flow, and
    model checking. Each of these tracing objectives have different
    flavors of visualization which pair with them. We overview these
    visualization techniques in Section~\ref{sec:related}
%%

We propose a tracing tool which captures state similar to a model
checking trace tools, with the exception that rather than logging
control flow, our tracing tool only logs a distributed programs state.
Such tracing is unconventional and does not fit nicely into the
aforementioned tracing categories. As such our unique requirements
demand innovative visualization solutions. Entirely state based program
analysis has ties in the world of trajectory
programming~\cite{Waterland:2014:AAS:2654822.2541985,181250,Waterland:2013:CC:2485732.2485749}.
In trajectory analysis simple ML techniques such as weather man, and
mean prediction, as well as linear, and logistic regression are used
to automatically predict and parrallelize computation based solely on
state analysis.

Our proposed visualization for traces of program state applies a similar ML
technique, t-SNE clustering which is a dimensionality reduction
algorithm~\cite{Hinton_visualizingdata}. we leverage t-SNE to clusters points in a programs
execution based on the similarities of a programs state.  T-SNE requires a
distancing function to cluster state, our distance function is as follows. The
distance between two trace points $p$ and $p'$, whose state is composed of an
identical set of variables with potentially different values $V \in \{v_1, v_2,
\dots v_m\}$ calculate the XOR of each pair of variables. Each one bit in the
resultant XOR is a difference of 1bit between the variables. We calculate the
difference between two variables as the number of one bits in the XOR. The
distance between trace points $p$ and $p'$ is the euclidean norm of all
variable distances.

We found the results of our initial technique promising, and the high level
behaviour of distributed programs we traced. However, our visualization suffers
due to a high level of computational complexity in running t-SNE. A single step
of the iterative t-SNE algorithm is $O(n)$, and the algorithm is typically
executed for greater that 20 iterations before a reasonable clustering is
obtained. Typical runtimes for traces consisting of 80 - 100 trace points,
containing 80 - 100 variables each resulted in runtimes in the tens of minutes.
This significant barrier to interactivity lead us to alter the architecture of
our tool, and implement parallel t-SNE to achieve interactive sub 10s
computation times. 

Our prototype visualization allowed users to inspect trace points, and
view individual variable values, without the ability to compare
points. All variables were weighted equally when computing weights.
Our interactivity goals are two fold first developers should be able
to query two points, and inspect variables which caused them to be
distant from one another. Second we acknowledge that all variables are
not of equal importance in a program. Some variables values
drastically alter the behaviour of a program while other do not. To
this end we extended our interface to support re-clustering with
increased weights for important user specified variables.

An additional feature of our tracing tool is the analysis of
distributed data invariants. We infer invariants using Dinv, a
distributed front end for Daikon~\cite{Ernst99dynamicallydiscovering}.
These invariants are inferred over entire traces of an execution, and
the number of invariants can be large and incomprehensible (300-400).
In addition to our improvements of t-SNE we refined our invariant
analysis by first, logically detecting t-SNE clusters using k-Means
clustering, deriving per cluster invariants, and refining those
further to unique invariants for each cluster. This processing step
greatly reduces spurious, and uninteresting invariants, and profiles
cluster behaviour more precisely.

The rest of the paper is laid out as follows.
Section~\ref{sec:related} covers related work. Section~\ref{sec:scope}
overviews the scope of our contributions, and Section~\ref{sec:imp}
covers our implementation. Section~\ref{sec:res} details our
performance results and data refinement accuracy. Finally
Section~\ref{sec:dafw} and Section~\ref{sec:conclusion} denote
potential future work, and the conclusion of the paper.
